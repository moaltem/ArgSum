{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument Quality Scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moritz/miniconda3/envs/AM/lib/python3.8/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/Users/moritz/miniconda3/envs/AM/lib/python3.8/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "loading configuration file config.json from cache at /Users/moritz/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_attentions\": true,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.33.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /Users/moritz/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/moritz/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/moritz/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.33.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /Users/moritz/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/model.safetensors\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from argsum.tools import train_quality_scorer, eval_quality_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ArgKP-2021 \n",
    "ArgKP21 = pd.read_csv('data/ArgKP-2021/dataset_splits_scores.csv')\n",
    "ArgKP21_train_topics = ArgKP21[ArgKP21['set'] == 'train']['topic'].unique()\n",
    "ArgKP21_dev_topics = ArgKP21[ArgKP21['set'] == 'dev']['topic'].unique()\n",
    "ArgKP21_test_topics = ArgKP21[ArgKP21['set'] == 'test']['topic'].unique()\n",
    "\n",
    "# Load ArgQ dataset\n",
    "ArgQ = pd.read_csv('data/IBM-ArgQ-Rank-30kArgs/dataset_scores.csv')\n",
    "ArgQ_train = ArgQ[ArgQ['topic'].isin(ArgKP21_train_topics)]\n",
    "ArgQ_dev = ArgQ[ArgQ['topic'].isin(ArgKP21_dev_topics)]\n",
    "\n",
    "test_set_mask = (ArgQ['set'] == 'test') & (~ArgQ['topic'].isin(ArgKP21_train_topics.tolist() + ArgKP21_dev_topics.tolist()))\n",
    "ArgQ_test = ArgQ[test_set_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, development and test topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Topics:\n",
      "\n",
      "We should abandon marriage\n",
      "Assisted suicide should be a criminal offence\n",
      "We should prohibit women in combat\n",
      "We should abolish capital punishment\n",
      "We should legalize sex selection\n",
      "We should ban human cloning\n",
      "We should fight urbanization\n",
      "We should introduce compulsory voting\n",
      "We should fight for the abolition of nuclear weapons\n",
      "We should adopt libertarianism\n",
      "We should prohibit flag burning\n",
      "We should legalize cannabis\n",
      "We should adopt atheism\n",
      "We should ban private military companies\n",
      "Homeschooling should be banned\n",
      "We should legalize prostitution\n",
      "We should end mandatory retirement\n",
      "We should abolish intellectual property rights\n",
      "The vow of celibacy should be abandoned\n",
      "We should subsidize vocational education\n",
      "We should close Guantanamo Bay detention camp\n",
      "We should ban the use of child actors\n",
      "We should subsidize journalism\n",
      "We should subsidize space exploration\n"
     ]
    }
   ],
   "source": [
    "print('Train Topics:\\n')\n",
    "\n",
    "for topic in ArgQ_train['topic'].unique():\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Topics:\n",
      "\n",
      "We should abolish the right to keep and bear arms\n",
      "We should abandon the use of school uniform\n",
      "We should adopt an austerity regime\n",
      "We should end affirmative action\n"
     ]
    }
   ],
   "source": [
    "print('Train Topics:\\n')\n",
    "\n",
    "for topic in ArgQ_dev['topic'].unique():\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Topics:\n",
      "\n",
      "Holocaust denial should be a criminal offence\n",
      "The use of public defenders should be mandatory\n",
      "We should ban factory farming\n",
      "We should abolish the three-strikes laws\n",
      "We should prohibit school prayer\n",
      "We should ban targeted killing\n",
      "Social media brings more harm than good\n",
      "We should ban algorithmic trading\n",
      "We should ban missionary work\n",
      "We should abolish the Olympic Games\n"
     ]
    }
   ],
   "source": [
    "print('Train Topics:\\n')\n",
    "\n",
    "for topic in ArgQ_test['topic'].unique():\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(ArgQ_train['topic'].unique()).intersection(set(ArgQ_dev['topic'].unique())).intersection(set(ArgQ_test['topic'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model for different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c7c2abcbf74387867dd8b3eecc7774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10324 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ebf7fe0cca4a9da6518cd80e7d856b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1775 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1541, 'learning_rate': 1.7523219814241487e-05, 'epoch': 0.62}\n",
      "{'eval_loss': 0.1050514429807663, 'eval_rmse': 0.34775906801223755, 'eval_p_corr': 0.47317079134091194, 'eval_s_corr': 0.44035769803739805, 'eval_runtime': 6.8048, 'eval_samples_per_second': 260.847, 'eval_steps_per_second': 8.23, 'epoch': 0.62}\n",
      "{'loss': 0.0996, 'learning_rate': 1.5046439628482974e-05, 'epoch': 1.24}\n",
      "{'eval_loss': 0.09904874861240387, 'eval_rmse': 0.3462628424167633, 'eval_p_corr': 0.49913317661069634, 'eval_s_corr': 0.4594649161342128, 'eval_runtime': 6.4327, 'eval_samples_per_second': 275.934, 'eval_steps_per_second': 8.706, 'epoch': 1.24}\n",
      "{'loss': 0.089, 'learning_rate': 1.256965944272446e-05, 'epoch': 1.86}\n",
      "{'eval_loss': 0.10298730432987213, 'eval_rmse': 0.3452208936214447, 'eval_p_corr': 0.4911572815096422, 'eval_s_corr': 0.4573436804802352, 'eval_runtime': 8.4149, 'eval_samples_per_second': 210.936, 'eval_steps_per_second': 6.655, 'epoch': 1.86}\n",
      "{'loss': 0.0702, 'learning_rate': 1.0092879256965946e-05, 'epoch': 2.48}\n",
      "{'eval_loss': 0.11116676777601242, 'eval_rmse': 0.33867979049682617, 'eval_p_corr': 0.49267267479944354, 'eval_s_corr': 0.4606871899370674, 'eval_runtime': 9.9874, 'eval_samples_per_second': 177.725, 'eval_steps_per_second': 5.607, 'epoch': 2.48}\n",
      "{'loss': 0.0643, 'learning_rate': 7.616099071207431e-06, 'epoch': 3.1}\n",
      "{'eval_loss': 0.11111962795257568, 'eval_rmse': 0.33979183435440063, 'eval_p_corr': 0.4967130132139051, 'eval_s_corr': 0.45658617359643827, 'eval_runtime': 7.8596, 'eval_samples_per_second': 225.84, 'eval_steps_per_second': 7.125, 'epoch': 3.1}\n",
      "{'loss': 0.0487, 'learning_rate': 5.139318885448917e-06, 'epoch': 3.72}\n",
      "{'eval_loss': 0.11114250868558884, 'eval_rmse': 0.338798463344574, 'eval_p_corr': 0.48695038660249657, 'eval_s_corr': 0.4545998874687811, 'eval_runtime': 7.5771, 'eval_samples_per_second': 234.257, 'eval_steps_per_second': 7.391, 'epoch': 3.72}\n",
      "{'loss': 0.0413, 'learning_rate': 2.662538699690403e-06, 'epoch': 4.33}\n",
      "{'eval_loss': 0.11291838437318802, 'eval_rmse': 0.3399428129196167, 'eval_p_corr': 0.4952159123395271, 'eval_s_corr': 0.45898536309654403, 'eval_runtime': 7.3365, 'eval_samples_per_second': 241.942, 'eval_steps_per_second': 7.633, 'epoch': 4.33}\n",
      "{'train_runtime': 747.1391, 'train_samples_per_second': 69.09, 'train_steps_per_second': 2.162, 'train_loss': 0.08102490629468645, 'epoch': 4.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9241954b8a424095b6560253d83069c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10324 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe4bbfded6f4a1da5e68c4b51544b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1775 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0847, 'learning_rate': 1.7523219814241487e-05, 'epoch': 0.62}\n",
      "{'eval_loss': 0.028995277360081673, 'eval_rmse': 0.21972905099391937, 'eval_p_corr': 0.49464174560467067, 'eval_s_corr': 0.42978126113975124, 'eval_runtime': 8.0713, 'eval_samples_per_second': 219.914, 'eval_steps_per_second': 6.938, 'epoch': 0.62}\n",
      "{'loss': 0.0291, 'learning_rate': 1.5046439628482974e-05, 'epoch': 1.24}\n",
      "{'eval_loss': 0.02699718251824379, 'eval_rmse': 0.21290089190006256, 'eval_p_corr': 0.5137796709638508, 'eval_s_corr': 0.44535175357629303, 'eval_runtime': 8.2756, 'eval_samples_per_second': 214.486, 'eval_steps_per_second': 6.767, 'epoch': 1.24}\n",
      "{'loss': 0.0268, 'learning_rate': 1.256965944272446e-05, 'epoch': 1.86}\n",
      "{'eval_loss': 0.026930633932352066, 'eval_rmse': 0.2128283679485321, 'eval_p_corr': 0.5117600348155743, 'eval_s_corr': 0.44420088938984204, 'eval_runtime': 7.5506, 'eval_samples_per_second': 235.081, 'eval_steps_per_second': 7.417, 'epoch': 1.86}\n",
      "{'loss': 0.0216, 'learning_rate': 1.0092879256965946e-05, 'epoch': 2.48}\n",
      "{'eval_loss': 0.027571693062782288, 'eval_rmse': 0.21266886591911316, 'eval_p_corr': 0.49603862950794847, 'eval_s_corr': 0.4294855964875788, 'eval_runtime': 7.3459, 'eval_samples_per_second': 241.632, 'eval_steps_per_second': 7.623, 'epoch': 2.48}\n",
      "{'loss': 0.0203, 'learning_rate': 7.616099071207431e-06, 'epoch': 3.1}\n",
      "{'eval_loss': 0.028461549431085587, 'eval_rmse': 0.20987237989902496, 'eval_p_corr': 0.4994216358237229, 'eval_s_corr': 0.4340685951948852, 'eval_runtime': 7.6523, 'eval_samples_per_second': 231.956, 'eval_steps_per_second': 7.318, 'epoch': 3.1}\n",
      "{'loss': 0.0157, 'learning_rate': 5.139318885448917e-06, 'epoch': 3.72}\n",
      "{'eval_loss': 0.029298551380634308, 'eval_rmse': 0.2084970474243164, 'eval_p_corr': 0.49694295626382196, 'eval_s_corr': 0.4289073772466202, 'eval_runtime': 7.4411, 'eval_samples_per_second': 238.541, 'eval_steps_per_second': 7.526, 'epoch': 3.72}\n",
      "{'loss': 0.0144, 'learning_rate': 2.662538699690403e-06, 'epoch': 4.33}\n",
      "{'eval_loss': 0.030271293595433235, 'eval_rmse': 0.2073250561952591, 'eval_p_corr': 0.49469342361603746, 'eval_s_corr': 0.4302258423840082, 'eval_runtime': 7.5147, 'eval_samples_per_second': 236.205, 'eval_steps_per_second': 7.452, 'epoch': 4.33}\n",
      "{'loss': 0.0131, 'learning_rate': 1.8575851393188855e-07, 'epoch': 4.95}\n",
      "{'eval_loss': 0.028976479545235634, 'eval_rmse': 0.20914830267429352, 'eval_p_corr': 0.49454987098320397, 'eval_s_corr': 0.4302580605486662, 'eval_runtime': 7.9295, 'eval_samples_per_second': 223.848, 'eval_steps_per_second': 7.062, 'epoch': 4.95}\n",
      "{'train_runtime': 878.3735, 'train_samples_per_second': 58.768, 'train_steps_per_second': 1.839, 'train_loss': 0.02822014018893242, 'epoch': 4.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d39d9de66c24a3bac22dd2e4a5ae7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10324 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae43b7e942404c4581dd0886dca46a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1775 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1135, 'learning_rate': 1.7523219814241487e-05, 'epoch': 0.62}\n",
      "{'eval_loss': 0.10458976030349731, 'eval_rmse': 0.32340338826179504, 'eval_p_corr': 0.46305680101238283, 'eval_s_corr': 0.42896611670875895, 'eval_runtime': 8.1778, 'eval_samples_per_second': 217.05, 'eval_steps_per_second': 6.848, 'epoch': 0.62}\n",
      "{'loss': 0.0941, 'learning_rate': 1.5046439628482974e-05, 'epoch': 1.24}\n",
      "{'eval_loss': 0.10314378142356873, 'eval_rmse': 0.32116004824638367, 'eval_p_corr': 0.49076064534666997, 'eval_s_corr': 0.44830432480488647, 'eval_runtime': 7.4569, 'eval_samples_per_second': 238.035, 'eval_steps_per_second': 7.51, 'epoch': 1.24}\n",
      "{'loss': 0.0808, 'learning_rate': 1.256965944272446e-05, 'epoch': 1.86}\n",
      "{'eval_loss': 0.10578076541423798, 'eval_rmse': 0.32523953914642334, 'eval_p_corr': 0.487155324613833, 'eval_s_corr': 0.44520598982936155, 'eval_runtime': 7.9739, 'eval_samples_per_second': 222.6, 'eval_steps_per_second': 7.023, 'epoch': 1.86}\n",
      "{'loss': 0.0637, 'learning_rate': 1.0092879256965946e-05, 'epoch': 2.48}\n",
      "{'eval_loss': 0.11527345329523087, 'eval_rmse': 0.3395194411277771, 'eval_p_corr': 0.4721791317014355, 'eval_s_corr': 0.448090177789478, 'eval_runtime': 7.8365, 'eval_samples_per_second': 226.504, 'eval_steps_per_second': 7.146, 'epoch': 2.48}\n",
      "{'loss': 0.0568, 'learning_rate': 7.616099071207431e-06, 'epoch': 3.1}\n",
      "{'eval_loss': 0.11288893967866898, 'eval_rmse': 0.33598950505256653, 'eval_p_corr': 0.4988595222459951, 'eval_s_corr': 0.4554208591821193, 'eval_runtime': 7.8943, 'eval_samples_per_second': 224.845, 'eval_steps_per_second': 7.094, 'epoch': 3.1}\n",
      "{'loss': 0.042, 'learning_rate': 5.139318885448917e-06, 'epoch': 3.72}\n",
      "{'eval_loss': 0.1112319827079773, 'eval_rmse': 0.33351460099220276, 'eval_p_corr': 0.49026810430254614, 'eval_s_corr': 0.4523948146539799, 'eval_runtime': 7.5702, 'eval_samples_per_second': 234.472, 'eval_steps_per_second': 7.397, 'epoch': 3.72}\n",
      "{'loss': 0.0351, 'learning_rate': 2.662538699690403e-06, 'epoch': 4.33}\n",
      "{'eval_loss': 0.11752693355083466, 'eval_rmse': 0.34282201528549194, 'eval_p_corr': 0.48608411681432395, 'eval_s_corr': 0.44479361788091043, 'eval_runtime': 7.6996, 'eval_samples_per_second': 230.532, 'eval_steps_per_second': 7.273, 'epoch': 4.33}\n",
      "{'train_runtime': 758.548, 'train_samples_per_second': 68.051, 'train_steps_per_second': 2.129, 'train_loss': 0.06943595818110875, 'epoch': 4.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8edfce6cf6d64ff5a9a1f173c3e54ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10324 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bee43b2c5884a408c915ee42c2e1389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1775 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0319, 'learning_rate': 1.7523219814241487e-05, 'epoch': 0.62}\n",
      "{'eval_loss': 0.027680937200784683, 'eval_rmse': 0.16637589037418365, 'eval_p_corr': 0.48942309773966325, 'eval_s_corr': 0.4316377085346035, 'eval_runtime': 8.1486, 'eval_samples_per_second': 217.828, 'eval_steps_per_second': 6.872, 'epoch': 0.62}\n",
      "{'loss': 0.0252, 'learning_rate': 1.5046439628482974e-05, 'epoch': 1.24}\n",
      "{'eval_loss': 0.02707560360431671, 'eval_rmse': 0.1645466536283493, 'eval_p_corr': 0.5041953715495292, 'eval_s_corr': 0.42840610164722454, 'eval_runtime': 7.5742, 'eval_samples_per_second': 234.347, 'eval_steps_per_second': 7.393, 'epoch': 1.24}\n",
      "{'loss': 0.0229, 'learning_rate': 1.256965944272446e-05, 'epoch': 1.86}\n",
      "{'eval_loss': 0.027422746643424034, 'eval_rmse': 0.16559815406799316, 'eval_p_corr': 0.5000947781225905, 'eval_s_corr': 0.42685444864246236, 'eval_runtime': 7.967, 'eval_samples_per_second': 222.795, 'eval_steps_per_second': 7.029, 'epoch': 1.86}\n",
      "{'loss': 0.0181, 'learning_rate': 1.0092879256965946e-05, 'epoch': 2.48}\n",
      "{'eval_loss': 0.027987804263830185, 'eval_rmse': 0.16729556024074554, 'eval_p_corr': 0.5031848946035019, 'eval_s_corr': 0.4297971900902013, 'eval_runtime': 7.6244, 'eval_samples_per_second': 232.806, 'eval_steps_per_second': 7.345, 'epoch': 2.48}\n",
      "{'loss': 0.0162, 'learning_rate': 7.616099071207431e-06, 'epoch': 3.1}\n",
      "{'eval_loss': 0.02913513034582138, 'eval_rmse': 0.1706901639699936, 'eval_p_corr': 0.4982971144183091, 'eval_s_corr': 0.42155045518549733, 'eval_runtime': 8.0349, 'eval_samples_per_second': 220.91, 'eval_steps_per_second': 6.97, 'epoch': 3.1}\n",
      "{'loss': 0.0125, 'learning_rate': 5.139318885448917e-06, 'epoch': 3.72}\n",
      "{'eval_loss': 0.028702855110168457, 'eval_rmse': 0.16941916942596436, 'eval_p_corr': 0.4994334859514204, 'eval_s_corr': 0.4237122739929409, 'eval_runtime': 7.605, 'eval_samples_per_second': 233.4, 'eval_steps_per_second': 7.364, 'epoch': 3.72}\n",
      "{'loss': 0.0107, 'learning_rate': 2.662538699690403e-06, 'epoch': 4.33}\n",
      "{'eval_loss': 0.02959849126636982, 'eval_rmse': 0.172042116522789, 'eval_p_corr': 0.49403066172943344, 'eval_s_corr': 0.4223974506431248, 'eval_runtime': 7.9045, 'eval_samples_per_second': 224.555, 'eval_steps_per_second': 7.085, 'epoch': 4.33}\n",
      "{'train_runtime': 763.4007, 'train_samples_per_second': 67.618, 'train_steps_per_second': 2.116, 'train_loss': 0.019631211757659913, 'epoch': 4.33}\n"
     ]
    }
   ],
   "source": [
    "for p in [True, False]:\n",
    "    for t in ['MACE-P', 'WA']:\n",
    "        train_quality_scorer(ArgQ_train, ArgQ_dev, target_name = t, pooling = p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare model performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     4.54it/s]\r"
     ]
    }
   ],
   "source": [
    "# Set model directories \n",
    "model_dirs = ['models/quality_scorer/bert_ft_topic_np_mace-p/2024-May-29_15-58-03',\n",
    "              'models/quality_scorer/bert_ft_topic_np_wa/2024-May-29_16-10-44',\n",
    "              'models/quality_scorer/bert_ft_topic_p_mace-p/2024-May-29_15-30-54',\n",
    "              'models/quality_scorer/bert_ft_topic_p_wa/2024-May-29_15-43-23']\n",
    "# Evaluate models \n",
    "for dir in model_dirs:\n",
    "    model = torch.load(dir + '/best_model.pt')\n",
    "    eval_quality_scorer(model, ArgQ_test, output_dir = dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ArgumentQualityClient: 100%|██████████| 4216/4216 [00:48<00:00, 86.23it/s] \n"
     ]
    }
   ],
   "source": [
    "# Evaluate debater api\n",
    "eval_quality_scorer('debater_api', ArgQ_test, output_dir = 'models/quality_scorer/debater_api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>macep_rmse_eval</th>\n",
       "      <th>macep_p_corr_eval</th>\n",
       "      <th>macep_s_corr_eval</th>\n",
       "      <th>wa_rmse_eval</th>\n",
       "      <th>wa_p_corr_eval</th>\n",
       "      <th>wa_s_corr_eval</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>np_mace-p</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.427</td>\n",
       "      <td>31.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>np_wa</th>\n",
       "      <td>0.400</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.409</td>\n",
       "      <td>30.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_mace-p</th>\n",
       "      <td>0.355</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.418</td>\n",
       "      <td>30.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_wa</th>\n",
       "      <td>0.374</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.396</td>\n",
       "      <td>31.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debater_api</th>\n",
       "      <td>0.427</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.461</td>\n",
       "      <td>48.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             macep_rmse_eval  macep_p_corr_eval  macep_s_corr_eval  \\\n",
       "np_mace-p              0.330              0.494              0.467   \n",
       "np_wa                  0.400              0.471              0.442   \n",
       "p_mace-p               0.355              0.482              0.457   \n",
       "p_wa                   0.374              0.459              0.434   \n",
       "debater_api            0.427              0.502              0.492   \n",
       "\n",
       "             wa_rmse_eval  wa_p_corr_eval  wa_s_corr_eval  runtime  \n",
       "np_mace-p           0.242           0.479           0.427   31.761  \n",
       "np_wa               0.169           0.474           0.409   30.719  \n",
       "p_mace-p            0.230           0.469           0.418   30.874  \n",
       "p_wa                0.212           0.455           0.396   31.284  \n",
       "debater_api         0.176           0.518           0.461   48.896  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dirs = ['models/quality_scorer/bert_ft_topic_np_mace-p/2024-May-29_15-58-03',\n",
    "              'models/quality_scorer/bert_ft_topic_np_wa/2024-May-29_16-10-44',\n",
    "              'models/quality_scorer/bert_ft_topic_p_mace-p/2024-May-29_15-30-54',\n",
    "              'models/quality_scorer/bert_ft_topic_p_wa/2024-May-29_15-43-23']\n",
    "\n",
    "# Load evaluation reports\n",
    "np_macep = pd.read_csv(model_dirs[0] + '/eval_report.csv')\n",
    "np_wa = pd.read_csv(model_dirs[1] + '/eval_report.csv')\n",
    "p_macep = pd.read_csv(model_dirs[2] + '/eval_report.csv')\n",
    "p_wa = pd.read_csv(model_dirs[3] + '/eval_report.csv')\n",
    "debater_api = pd.read_csv('models/quality_scorer/debater_api/eval_report.csv')\n",
    "# Set model names\n",
    "model_names = ['np_mace-p', 'np_wa', 'p_mace-p', 'p_wa', 'debater_api']\n",
    "# Print concatenated evaluation reports\n",
    "results = pd.concat([np_macep, np_wa, p_macep, p_wa, debater_api])\n",
    "results.index = model_names\n",
    "results.round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
