{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster-based Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moritz/miniconda3/envs/AM/lib/python3.8/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/Users/moritz/miniconda3/envs/AM/lib/python3.8/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "loading configuration file config.json from cache at /Users/moritz/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_attentions\": true,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.33.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /Users/moritz/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/moritz/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/moritz/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.33.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /Users/moritz/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/model.safetensors\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "from tqdm.notebook import tqdm\n",
    "from argsum import load_test_df, get_summetix_cluster_sums, get_t5_cluster_sums, get_llm_cluster_sums\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArgKP21 = load_test_df('ArgKP21')\n",
    "Debate_test = load_test_df('Debate_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_sums(df, cluster_dict, get_cluster_sums_callable, parameter_dict, output_dir = 'investigations/2_cluster_summaries', file_name = None):\n",
    "\n",
    "    # Get cluster parameter names and values\n",
    "    clu_parameter_names = cluster_dict['parameter_names']\n",
    "    clu_parameter_values = cluster_dict['parameter_values']\n",
    "    clu_parameter_combinations = list(product(*clu_parameter_values))\n",
    "\n",
    "    # Get unique topics and stances\n",
    "    topics = df['topic'].unique().tolist()\n",
    "    stances = [str(int(sta)) for sta in sorted(df['stance'].unique())]\n",
    "\n",
    "    # Get parameter for iteration\n",
    "    iterate_parameter_names = [item[0] for item in parameter_dict.items() if type(item[1]) == list]\n",
    "    iterate_parameter_values = [parameter_dict[parameter_name] for parameter_name in iterate_parameter_names]\n",
    "    iter_parameter_value_combinations = list(product(*iterate_parameter_values))\n",
    "\n",
    "    # Create empty dict to store the clusters\n",
    "    results = dict(zip(['summaries', 'clu_parameter_names', 'clu_parameter_values', 'sum_parameter_names', 'sum_parameter_values'], [dict(zip([str(comb) for comb in clu_parameter_combinations], [dict(zip(topics, [dict(zip(stances, [dict(zip([str(comb) for comb in iter_parameter_value_combinations], [dict(zip(['sums', 'runtime'], [None, None])) for i in range(len(iter_parameter_value_combinations))])) for i in range(len(stances))])) for i in range(len(topics))])) for i in range(len(clu_parameter_combinations))]))] + [dict(zip([str(comb) for comb in clu_parameter_combinations], [dict(zip(topics, [dict(zip(stances, [dict(zip([str(comb) for comb in iter_parameter_value_combinations], [dict(zip(['sums', 'runtime'], [None, None])) for i in range(len(iter_parameter_value_combinations))])) for i in range(len(stances))])) for i in range(len(topics))])) for i in range(len(clu_parameter_combinations))]))] + [clu_parameter_names, clu_parameter_values ,iterate_parameter_names, iterate_parameter_values]))\n",
    "        \n",
    "    ################################\n",
    "    ### Iterate: topic & stance ####\n",
    "    ################################\n",
    "\n",
    "    for topic_stance in tqdm([(topic, stance) for topic in topics for stance in stances], leave = True, desc = 'topic + stance'):\n",
    "        \n",
    "        topic = topic_stance[0]\n",
    "        stance = topic_stance[1]\n",
    "        mask_topic_stance = (df['topic'] == topic) & (df['stance'] == int(stance))\n",
    "        arguments = df[mask_topic_stance]['argument'].to_list()\n",
    "\n",
    "        ##########################################\n",
    "        ### Iterate: cluster parameter values ####\n",
    "        ##########################################\n",
    "\n",
    "        for clu_parameter in tqdm(clu_parameter_combinations, leave = True, desc = 'clustering parameter'):\n",
    "            \n",
    "            if 'iterative_clustering' in cluster_dict.keys():\n",
    "                cluster_ids = cluster_dict['iterative_clustering'][str(clu_parameter)][topic][stance]['cluster_ids']\n",
    "                clustering_runtime = cluster_dict['iterative_clustering'][str(clu_parameter)][topic][stance]['runtime']   \n",
    "            else:    \n",
    "                cluster_ids = cluster_dict['clustering'][str(clu_parameter)][topic][stance]['cluster_ids']\n",
    "                clustering_runtime = cluster_dict['clustering'][str(clu_parameter)][topic][stance]['runtime']\n",
    "   \n",
    "            cluster_ids_no_noise = [cluster_ids[i] for i in range(len(cluster_ids)) if cluster_ids[i] != -1]\n",
    "            arguments_no_noise = [arguments[i] for i in range(len(cluster_ids)) if cluster_ids[i] != -1]\n",
    "\n",
    "            cond_1 = (len(set(cluster_ids_no_noise)) > 1) # Number of clusters > 1\n",
    "            cond_2 = ((len(cluster_ids_no_noise) / len(cluster_ids)) > 0.5) # Proportion of clustered arguments > 50%\n",
    "\n",
    "            ############################\n",
    "            ### Iterate: parameter #####\n",
    "            ############################\n",
    "\n",
    "            # Only if the conditions are true\n",
    "            if cond_1 & cond_2:\n",
    "\n",
    "                for comb in tqdm(iter_parameter_value_combinations, leave = False, disable = True, desc = 'summarization parameter'):\n",
    "                    iterate_parameter_dict = {**parameter_dict, **dict(zip(iterate_parameter_names, list(comb)))}\n",
    "\n",
    "                    ########################\n",
    "                    ### Get summaries ######\n",
    "                    ########################\n",
    "\n",
    "                    try:\n",
    "                        start_time = time()\n",
    "                        cluster_sums = get_cluster_sums_callable(arguments_no_noise, cluster_ids_no_noise, topic = topic, stance = int(stance), **iterate_parameter_dict)\n",
    "                        runtime = time() - start_time\n",
    "                    except:\n",
    "                        cluster_sums = None\n",
    "                        runtime= None\n",
    "\n",
    "                    results['summaries'][str(clu_parameter)][topic][stance][str(comb)]['sums'] = cluster_sums\n",
    "                    if runtime != None:\n",
    "                        results['summaries'][str(clu_parameter)][topic][stance][str(comb)]['runtime'] = np.round(clustering_runtime + runtime, 3)\n",
    "\n",
    "    ########################\n",
    "    ### Save results #######\n",
    "    ########################\n",
    "\n",
    "    if file_name != None:\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        with open(output_dir + '/' + file_name, 'w') as file:\n",
    "            json.dump(results, file)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summetix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('investigations/1_argument_clusters/ArgKP21_Summetix.json') as f:\n",
    "    summetix_cluster_dict = json.load(f)\n",
    "\n",
    "summetix_parameter_dict = {}\n",
    "\n",
    "summetix_results = get_cluster_sums(df = ArgKP21,\n",
    "                                    cluster_dict = summetix_cluster_dict,\n",
    "                                    get_cluster_sums_callable = get_summetix_cluster_sums,\n",
    "                                    parameter_dict = summetix_parameter_dict,\n",
    "                                    file_name = 'ArgKP21_Summetix.json'\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('investigations/1_argument_clusters/Debate_test_Summetix.json') as f:\n",
    "    summetix_cluster_dict = json.load(f)\n",
    "\n",
    "summetix_parameter_dict = {}\n",
    "\n",
    "summetix_results = get_cluster_sums(df = Debate_test,\n",
    "                                    cluster_dict = summetix_cluster_dict,\n",
    "                                    get_cluster_sums_callable = get_summetix_cluster_sums,\n",
    "                                    parameter_dict = summetix_parameter_dict,\n",
    "                                    file_name = 'Debate_test_Summetix.json'\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USKPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('investigations/1_argument_clusters/ArgKP21_USKPM.json') as f:\n",
    "    uskpm_cluster_dict = json.load(f)\n",
    "\n",
    "uskpm_parameter_dict = {'max_length_text':512, \n",
    "                        'max_length_label':128,\n",
    "                        'n': 5, \n",
    "                        'num_beams':6,\n",
    "                        'temperature':None,\n",
    "                        'do_sample':False, \n",
    "                        'p':None\n",
    "                        }\n",
    "\n",
    "uskpm_results = get_cluster_sums(df = ArgKP21,\n",
    "                                 cluster_dict = uskpm_cluster_dict,\n",
    "                                 get_cluster_sums_callable = get_t5_cluster_sums,\n",
    "                                 parameter_dict = uskpm_parameter_dict,\n",
    "                                 file_name = 'ArgKP21_USKPM.json'\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('investigations/1_argument_clusters/Debate_test_USKPM.json') as f:\n",
    "    uskpm_cluster_dict = json.load(f)\n",
    "\n",
    "uskpm_parameter_dict = {'max_length_text':512, \n",
    "                        'max_length_label':128,\n",
    "                        'n': 5, \n",
    "                        'num_beams':6,\n",
    "                        'temperature':None,\n",
    "                        'do_sample':False, \n",
    "                        'p':None\n",
    "                        }\n",
    "\n",
    "uskpm_results = get_cluster_sums(df = Debate_test,\n",
    "                                 cluster_dict = uskpm_cluster_dict,\n",
    "                                 get_cluster_sums_callable = get_t5_cluster_sums,\n",
    "                                 parameter_dict = uskpm_parameter_dict,\n",
    "                                 file_name = 'Debate_test_USKPM.json'\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCArgSum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('investigations/1_argument_clusters/ArgKP21_MCArgSum_SBERT_all_mpnet_base.json') as f:\n",
    "    mc_argsum_cluster_dict = json.load(f)\n",
    "\n",
    "mc_argsum_local_parameter_dict = {'llm':'gpt-3.5-turbo',\n",
    "                                  'optimization':'local', \n",
    "                                  'sum_token_length':8, \n",
    "                                  'sum_min_num':1, \n",
    "                                  'sum_max_num':1,\n",
    "                                  'few_shot':True, \n",
    "                                  'exclude_topic':False, \n",
    "                                  'generate_less':False,\n",
    "                                  'temperature':0.5,\n",
    "                                  'frequency_penalty':None, \n",
    "                                  'n':5,\n",
    "                                  'p':None\n",
    "                                  }\n",
    "\n",
    "mc_argsum_local_results = get_cluster_sums(df = ArgKP21,\n",
    "                                           cluster_dict = mc_argsum_cluster_dict,\n",
    "                                           get_cluster_sums_callable = get_llm_cluster_sums,\n",
    "                                           parameter_dict = mc_argsum_local_parameter_dict,\n",
    "                                           file_name = 'ArgKP21_MCArgSum_SBERT_all_mpnet_base_local.json'\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('investigations/1_argument_clusters/Debate_test_MCArgSum_SBERT_all_mpnet_base.json') as f:\n",
    "    mc_argsum_cluster_dict = json.load(f)\n",
    "\n",
    "mc_argsum_local_parameter_dict = {'llm':'gpt-3.5-turbo',\n",
    "                                  'optimization':'local', \n",
    "                                  'sum_token_length':8, \n",
    "                                  'sum_min_num':1, \n",
    "                                  'sum_max_num':1,\n",
    "                                  'few_shot':True, \n",
    "                                  'exclude_topic':False, \n",
    "                                  'generate_less':False,\n",
    "                                  'temperature':0.5,\n",
    "                                  'frequency_penalty':None, \n",
    "                                  'n':5,\n",
    "                                  'p':None\n",
    "                                  }\n",
    "\n",
    "mc_argsum_local_results = get_cluster_sums(df = Debate_test,\n",
    "                                           cluster_dict = mc_argsum_cluster_dict,\n",
    "                                           get_cluster_sums_callable = get_llm_cluster_sums,\n",
    "                                           parameter_dict = mc_argsum_local_parameter_dict,\n",
    "                                           file_name = 'Debate_test_MCArgSum_SBERT_all_mpnet_base_local.json'\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('investigations/1_argument_clusters/ArgKP21_MCArgSum_SBERT_all_mpnet_base.json') as f:\n",
    "    mc_argsum_cluster_dict = json.load(f)\n",
    "\n",
    "mc_argsum_local_parameter_dict = {'llm':'gpt-3.5-turbo',\n",
    "                                  'optimization':'global', \n",
    "                                  'sum_token_length':8, \n",
    "                                  'sum_min_num':1, \n",
    "                                  'sum_max_num':1,\n",
    "                                  'few_shot':True, \n",
    "                                  'exclude_topic':False, \n",
    "                                  'generate_less':False,\n",
    "                                  'temperature':0.5,\n",
    "                                  'frequency_penalty':None, \n",
    "                                  'n':5,\n",
    "                                  'p':None\n",
    "                                  }\n",
    "\n",
    "mc_argsum_local_results = get_cluster_sums(df = ArgKP21,\n",
    "                                           cluster_dict = mc_argsum_cluster_dict,\n",
    "                                           get_cluster_sums_callable = get_llm_cluster_sums,\n",
    "                                           parameter_dict = mc_argsum_local_parameter_dict,\n",
    "                                           file_name = 'ArgKP21_MCArgSum_SBERT_all_mpnet_base_global.json'\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('investigations/1_argument_clusters/Debate_test_MCArgSum_SBERT_all_mpnet_base.json') as f:\n",
    "    mc_argsum_cluster_dict = json.load(f)\n",
    "\n",
    "mc_argsum_local_parameter_dict = {'llm':'gpt-3.5-turbo',\n",
    "                                  'optimization':'global', \n",
    "                                  'sum_token_length':8, \n",
    "                                  'sum_min_num':1, \n",
    "                                  'sum_max_num':1,\n",
    "                                  'few_shot':True, \n",
    "                                  'exclude_topic':False, \n",
    "                                  'generate_less':False,\n",
    "                                  'temperature':0.5,\n",
    "                                  'frequency_penalty':None, \n",
    "                                  'n':5,\n",
    "                                  'p':None\n",
    "                                  }\n",
    "\n",
    "mc_argsum_local_results = get_cluster_sums(df = Debate_test,\n",
    "                                           cluster_dict = mc_argsum_cluster_dict,\n",
    "                                           get_cluster_sums_callable = get_llm_cluster_sums,\n",
    "                                           parameter_dict = mc_argsum_local_parameter_dict,\n",
    "                                           file_name = 'Debate_test_MCArgSum_SBERT_all_mpnet_base_global.json'\n",
    "                                           )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
